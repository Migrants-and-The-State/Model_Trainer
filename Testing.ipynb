{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore all these, Old Stuff too much confusion if looked againa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a1ac3901c673>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Classification Layer 1'] = df_filtered['Classification Layer 1'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "df['pkl_index'] = df.index\n",
    "df_filtered = df[df['Classification Layer 1'].isin([\"1\", \"2\", \"3\"])]\n",
    "df_filtered['Classification Layer 1'] = df_filtered['Classification Layer 1'].astype(int)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = shuffle(df_filtered)\n",
    "\n",
    "# Split the DataFrame into features (X) and labels (y)\n",
    "X = df_shuffled.drop('Classification Layer 1', axis=1)  # Assuming 'Classification Layer 1' is the target column\n",
    "y = df_shuffled['Classification Layer 1']\n",
    "\n",
    "# Random downsampling class 1 to match the size of class 2\n",
    "class_1_count = df_shuffled['Classification Layer 1'].value_counts()[1]\n",
    "class_2_count = df_shuffled['Classification Layer 1'].value_counts()[2]\n",
    "class_3_count = df_shuffled['Classification Layer 1'].value_counts()[3]\n",
    "\n",
    "# Downsampling class 1\n",
    "df_class_1 = df_shuffled[df_shuffled['Classification Layer 1'] == 1]\n",
    "df_class_1_downsampled = df_class_1.sample(n=class_2_count, replace=False)\n",
    "\n",
    "# Combining class 2, class 3, and downsampled class 1\n",
    "df_combined = pd.concat([df_shuffled[df_shuffled['Classification Layer 1'] == 2],\n",
    "                         df_shuffled[df_shuffled['Classification Layer 1'] == 3],\n",
    "                         df_class_1_downsampled])\n",
    "\n",
    "df_combined['Classification Layer 1'] = df_combined['Classification Layer 1'] - 1\n",
    "# Split the combined DataFrame into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_combined,\n",
    "                                                    df_combined['Classification Layer 1'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Optionally, you can save the train and test sets as separate CSV files\n",
    "\n",
    "X_train.to_csv('train2.csv', index=False)\n",
    "X_test.to_csv('test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afile</th>\n",
       "      <th>pno</th>\n",
       "      <th>full_url</th>\n",
       "      <th>Images</th>\n",
       "      <th>redacted</th>\n",
       "      <th>Classification Layer 1</th>\n",
       "      <th>Form/Letter/Photo/Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>A10394732</td>\n",
       "      <td>18</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>A10430675</td>\n",
       "      <td>114</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>A10296495</td>\n",
       "      <td>6</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>A10294862</td>\n",
       "      <td>15</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A10009114</td>\n",
       "      <td>12</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>A10548508</td>\n",
       "      <td>11</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A10009114</td>\n",
       "      <td>18</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>A10294862</td>\n",
       "      <td>139</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>A10294862</td>\n",
       "      <td>212</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>A10430675</td>\n",
       "      <td>145</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          afile  pno                                           full_url  \\\n",
       "715   A10394732   18  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "863   A10430675  114  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "581   A10296495    6  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "305   A10294862   15  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "39    A10009114   12  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "...         ...  ...                                                ...   \n",
       "1128  A10548508   11  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "45    A10009114   18  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "429   A10294862  139  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "502   A10294862  212  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "894   A10430675  145  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "\n",
       "      Images  redacted  Classification Layer 1  Form/Letter/Photo/Misc  \n",
       "715      NaN     False                       2                     2.0  \n",
       "863      NaN     False                       2                     2.0  \n",
       "581      NaN     False                       2                     1.0  \n",
       "305      NaN      True                       2                     1.0  \n",
       "39       NaN     False                       2                     2.0  \n",
       "...      ...       ...                     ...                     ...  \n",
       "1128     NaN     False                       1                     1.0  \n",
       "45       NaN     False                       1                     1.0  \n",
       "429      NaN      True                       1                     1.0  \n",
       "502      NaN      True                       1                     1.0  \n",
       "894      NaN     False                       1                     1.0  \n",
       "\n",
       "[793 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    266\n",
       "1    254\n",
       "3    114\n",
       "Name: Classification Layer 1, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Classification Layer 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/ag8172/test/ModelTraining/Images/train.csv')\n",
    "df['Classification Layer 1'] = df['Classification Layer 1']-1\n",
    "df.to_csv('/home/ag8172/test/ModelTraining/Images/train1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>afile</th>\n",
       "      <th>pno</th>\n",
       "      <th>full_url</th>\n",
       "      <th>Images</th>\n",
       "      <th>redacted</th>\n",
       "      <th>Classification Layer 1</th>\n",
       "      <th>Form/Letter/Photo/Misc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10430675</td>\n",
       "      <td>38</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A10294862</td>\n",
       "      <td>260</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A10139321</td>\n",
       "      <td>14</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A10430675</td>\n",
       "      <td>135</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A10179278</td>\n",
       "      <td>8</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>A10168178</td>\n",
       "      <td>37</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>A10534184</td>\n",
       "      <td>109</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>A10017891</td>\n",
       "      <td>44</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>A10534184</td>\n",
       "      <td>94</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>A10294862</td>\n",
       "      <td>155</td>\n",
       "      <td>https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         afile  pno                                           full_url  \\\n",
       "0    A10430675   38  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "1    A10294862  260  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "2    A10139321   14  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "3    A10430675  135  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "4    A10179278    8  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "..         ...  ...                                                ...   \n",
       "629  A10168178   37  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "630  A10534184  109  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "631  A10017891   44  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "632  A10534184   94  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "633  A10294862  155  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...   \n",
       "\n",
       "     Images  redacted  Classification Layer 1  Form/Letter/Photo/Misc  \n",
       "0       NaN     False                       1                     2.0  \n",
       "1       NaN      True                       2                     1.0  \n",
       "2       NaN     False                       1                     2.0  \n",
       "3       NaN     False                       1                     2.0  \n",
       "4       NaN      True                       0                     1.0  \n",
       "..      ...       ...                     ...                     ...  \n",
       "629     NaN     False                       1                     2.0  \n",
       "630     NaN      True                       1                     2.0  \n",
       "631     NaN      True                       1                     2.0  \n",
       "632     NaN      True                       2                     3.0  \n",
       "633     NaN      True                       1                     2.0  \n",
       "\n",
       "[634 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "afile                                                             A10430675\n",
       "pno                                                                      38\n",
       "full_url                  https://d1b7k5w7yjwpfg.cloudfront.net/iiif/2/m...\n",
       "Images                                                                  NaN\n",
       "redacted                                                              False\n",
       "Classification Layer 1                                                    1\n",
       "Form/Letter/Photo/Misc                                                    2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ag8172/.local/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Loaded Configs\n",
      "method:: <class 'torchvision.transforms.transforms.Resize'> params:: [[256, 256]]\n",
      "method:: <class 'torchvision.transforms.transforms.Normalize'> params:: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
      "method:: <class 'torchvision.transforms.transforms.Resize'> params:: [[256, 256]]\n",
      "method:: <class 'torchvision.transforms.transforms.Normalize'> params:: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
      "Initializng Dataset with file path ::: /home/ag8172/test/ModelTraining/Images/train1.csv\n",
      "Initializng Dataset with file path ::: /home/ag8172/test/ModelTraining/Images/test.csv\n",
      "Url Column :2     \n",
      " Labels Column :5\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Model Successfully created\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mag8172\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/ag8172/test/ModelTraining/Images/wandb/run-20240202_184737-wgoc59ui\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdistinctive-wave-43\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/runs/wgoc59ui\u001b[0m\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:16<01:06, 16.68s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:32<00:48, 16.01s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:48<00:32, 16.07s/it]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [01:04<00:16, 16.21s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [01:20<00:00, 16.03s/it]\u001b[A\n",
      "Epoch [1/5], Loss: 1.1547\n",
      "Evaluating\n",
      "\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 1/2 [00:16<00:16, 16.38s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:20<00:00, 10.19s/it]\u001b[A\n",
      "tensor([2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "        0, 0, 0, 0, 0, 0], device='cuda:0') tensor([2, 1, 3, 1, 1, 2, 3, 2, 2, 2, 3, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 3, 2,\n",
      "        2, 1, 1, 2, 1, 1], device='cuda:0')\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Accuracy: 0.0506, Precision: 0.4260, Recall: 0.0506, F1 Score: 0.0905\n",
      " 20%|████████▊                                   | 1/5 [01:40<06:42, 100.53s/it]\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:15<01:02, 15.53s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:31<00:48, 16.03s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:46<00:31, 15.57s/it]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [01:01<00:15, 15.13s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [01:15<00:00, 15.13s/it]\u001b[A\n",
      "Epoch [2/5], Loss: 1.0528\n",
      "Evaluating\n",
      "\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 1/2 [00:14<00:14, 14.84s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:18<00:00,  9.08s/it]\u001b[A\n",
      "tensor([0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0], device='cuda:0') tensor([2, 2, 1, 3, 1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 2, 2, 2, 3, 2, 1, 2, 1, 3, 2,\n",
      "        3, 1, 2, 2, 2, 2], device='cuda:0')\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Accuracy: 0.0886, Precision: 0.3599, Recall: 0.0886, F1 Score: 0.1225\n",
      " 40%|██████████████████                           | 2/5 [03:14<04:49, 96.59s/it]\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:14<00:58, 14.67s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# know whether we've finished (if we matched EOF) or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0mres_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# Still have time left, so read more data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mread_nonblocking\u001b[0;34m(self, size, timeout)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# (possibly timeout=None), we call select() with a timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mselect_ignore_interrupts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild_fd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/pexpect/utils.py\u001b[0m in \u001b[0;36mselect_ignore_interrupts\u001b[0;34m(iwtd, owtd, ewtd, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miwtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewtd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a3e5c46a4bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python main.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# Ensure the subprocess really is terminated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;31m# add isalive check, to ensure exitstatus is set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python/3.8.6/intel/lib/python3.8/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGCONT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterterminate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ag8172/.local/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import torchvision.transforms as transforms\n",
    "from customloader import get_data_loader\n",
    "# from model import CustomModel\n",
    "from trainer import Trainer\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def get_transforms(transform_config):\n",
    "    \n",
    "    transform_list = []\n",
    "    for transform_name, params in transform_config.items():\n",
    "        transform_method = getattr(transforms, transform_name)\n",
    "        if isinstance(params, list):\n",
    "            print(\"method::\",transform_method,\"params::\",params)\n",
    "            transform = transform_method(*params)\n",
    "        elif params is None:  # For transforms that do not require parameters\n",
    "            transform = transform_method()\n",
    "        else:\n",
    "            transform = transform_method(params)\n",
    "\n",
    "        transform_list.append(transform)\n",
    "\n",
    "    composed_transforms = transforms.Compose(transform_list)\n",
    "    return composed_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, architecture, num_classes=2, pretrained=False, transfer_learning=False):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # Dynamically get the model constructor\n",
    "        if hasattr(models, architecture):\n",
    "            model_constructor = getattr(models, architecture)\n",
    "            self.model = model_constructor(pretrained=pretrained)\n",
    "        else:\n",
    "            raise ValueError(f\"Model architecture '{architecture}' is not recognized.\")\n",
    "    \n",
    "        # Replace the classifier/FC layer for the given number of classes\n",
    "        if 'resnet' in architecture:\n",
    "            self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        elif 'vgg' in architecture:\n",
    "            self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
    "        elif 'alexnet' in architecture:\n",
    "            self.model.classifier[6] = nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
    "        else:\n",
    "            # You might want to handle other architectures or raise an error\n",
    "            pass\n",
    "\n",
    "        # Implement transfer learning\n",
    "        if transfer_learning:\n",
    "            # Freeze all layers\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # Unfreeze the last layer\n",
    "            if 'resnet' in architecture:\n",
    "                self.model.fc.weight.requires_grad = True\n",
    "                self.model.fc.bias.requires_grad = True\n",
    "            elif 'vgg' in architecture or 'alexnet' in architecture:\n",
    "                self.model.classifier[6].weight.requires_grad = True\n",
    "                self.model.classifier[6].bias.requires_grad = True\n",
    "           \n",
    "        else:\n",
    "            # Unfreeze all layers\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "class Trainer:\n",
    "    def __init__(self, model, dataloader, test_dataloader, epochs, learning_rate, device):\n",
    "        self.model = model.to(device)\n",
    "        self.dataloader = dataloader\n",
    "        self.epochs = epochs\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.device = device\n",
    "        self.test_dataloader = test_dataloader\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for inputs, labels in tqdm(self.dataloader):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)# labels.type(torch.LongTensor).to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(self.dataloader)\n",
    "        return avg_loss\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(self.epochs)):\n",
    "            avg_loss = self.train_epoch()\n",
    "            print(f\"Epoch [{epoch + 1}/{self.epochs}], Loss: {avg_loss:.4f}\")\n",
    "            wandb.log({\"Epoch\": epoch, \"Loss\": avg_loss})\n",
    "            self.evaluate()\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        print(\"Evaluating\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(self.test_dataloader):\n",
    "                inputs, labels = inputs.to(self.device), labels.type(torch.LongTensor).to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "#         print(preds,labels)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "        recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "#         auc = roc_auc_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "        wandb.log({\"Test Accuracy\": accuracy, \"Test Precision\": precision, \"Test Recall\": recall, \"Test F1 Score\": f1})\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Configs\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Url Column :2 \n",
      " Labels Column :5\n",
      "Model Successfully created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4vnld9np) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f145161f93544983946839a109f0ef7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-planet-40</strong> at: <a href='https://wandb.ai/ag8172/trial_run1/runs/4vnld9np' target=\"_blank\">https://wandb.ai/ag8172/trial_run1/runs/4vnld9np</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240202_182138-4vnld9np/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4vnld9np). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ee3248e8ee40b1bb7e9530b441dcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113345664408471, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ag8172/test/ModelTraining/Images/wandb/run-20240202_182201-mcfbc4p5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ag8172/trial_run1/runs/mcfbc4p5' target=\"_blank\">cool-deluge-41</a></strong> to <a href='https://wandb.ai/ag8172/trial_run1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ag8172/trial_run1' target=\"_blank\">https://wandb.ai/ag8172/trial_run1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ag8172/trial_run1/runs/mcfbc4p5' target=\"_blank\">https://wandb.ai/ag8172/trial_run1/runs/mcfbc4p5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a21f329c9744d2891c819f679aa8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28d1c2552d14c26aa490fb37c36030f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.2769\n",
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133cfc1f2d9c4cf68fa07bed0f0026d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8023, Precision: 0.8034, Recall: 0.8023, F1 Score: 0.8021\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e03c23459847719fc9a7918ec65c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.5714\n",
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ec8a6975e542f9924198dbdf01ba02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8663, Precision: 0.8667, Recall: 0.8663, F1 Score: 0.8661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22417875f1134db5bc311c6df2dae82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.4063\n",
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a84f32b108446e5a648fbc7e06abcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8901, Precision: 0.8900, Recall: 0.8901, F1 Score: 0.8899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1815e29bb1f347f09dea8c8fa5822d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.3305\n",
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd753813ed74ba18fb5bc36f00ca2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9029, Precision: 0.9029, Recall: 0.9029, F1 Score: 0.9028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516717eb6cc142b7a31e811856aff2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.2850\n",
      "Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb43742b139348d580a0bffb0d8e00b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9112, Precision: 0.9114, Recall: 0.9112, F1 Score: 0.9113\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "config = load_config('config.yaml')\n",
    "print(\"Loaded Configs\")\n",
    "# train_transform = get_transforms(config['transforms']['train'])\n",
    "# test_transform = get_transforms(config['transforms']['test'])\n",
    "# #     csv_file, labels_col, urls_col, batch_size, transform\n",
    "# train_loader = get_data_loader(config['data']['train_csv'], \n",
    "#                                config['train']['annotations'],\n",
    "#                                config['train']['image_url'], \n",
    "#                                config['data']['batch_size'],\n",
    "#                                train_transform)\n",
    "\n",
    "# test_loader = get_data_loader(config['data']['test_csv'],\n",
    "#                               config['train']['annotations'], \n",
    "#                               config['train']['image_url'],\n",
    "#                               config['data']['batch_size'],\n",
    "#                               test_transform)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet expects images of size 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet expects images of size 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "print(f\"Url Column :{config['train']['image_url']} \\\n",
    "\\n Labels Column :{config['train']['annotations']}\")\n",
    "model = CustomModel('resnet18', \n",
    "                    num_classes=10, \n",
    "                    pretrained=True,\n",
    "                   transfer_learning=False)\n",
    "print(\"Model Successfully created\")\n",
    "wandb.init(project=config['logging']['project_name'], entity=config['logging']['user_name'])\n",
    "trainer = Trainer(model, train_loader, test_loader,5, 0.001, config['train']['device'])\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ag8172/.local/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet expects images of size 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ag8172/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ag8172/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 10)  # CIFAR-10 has 10 classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.362\n",
      "[1,   200] loss: 0.577\n",
      "[1,   300] loss: 0.409\n",
      "[1,   400] loss: 0.337\n",
      "[1,   500] loss: 0.317\n",
      "[1,   600] loss: 0.272\n",
      "[1,   700] loss: 0.260\n",
      "[2,   100] loss: 0.185\n",
      "[2,   200] loss: 0.187\n",
      "[2,   300] loss: 0.180\n",
      "[2,   400] loss: 0.181\n",
      "[2,   500] loss: 0.176\n",
      "[2,   600] loss: 0.160\n",
      "[2,   700] loss: 0.159\n",
      "[3,   100] loss: 0.112\n",
      "[3,   200] loss: 0.111\n",
      "[3,   300] loss: 0.098\n",
      "[3,   400] loss: 0.107\n",
      "[3,   500] loss: 0.100\n",
      "[3,   600] loss: 0.100\n",
      "[3,   700] loss: 0.106\n",
      "[4,   100] loss: 0.064\n",
      "[4,   200] loss: 0.065\n",
      "[4,   300] loss: 0.062\n",
      "[4,   400] loss: 0.066\n",
      "[4,   500] loss: 0.062\n",
      "[4,   600] loss: 0.061\n",
      "[4,   700] loss: 0.064\n",
      "[5,   100] loss: 0.039\n",
      "[5,   200] loss: 0.037\n",
      "[5,   300] loss: 0.036\n",
      "[5,   400] loss: 0.040\n",
      "[5,   500] loss: 0.033\n",
      "[5,   600] loss: 0.036\n",
      "[5,   700] loss: 0.035\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(5):  # loop over the dataset multiple times, fewer epochs needed\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.09%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out Overall Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Configs\n",
      "method:: <class 'torchvision.transforms.transforms.Resize'> params:: [[256, 256]]\n",
      "method:: <class 'torchvision.transforms.transforms.Normalize'> params:: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
      "method:: <class 'torchvision.transforms.transforms.Resize'> params:: [[256, 256]]\n",
      "method:: <class 'torchvision.transforms.transforms.Normalize'> params:: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
      "Loading Embeddings from Pkl\n",
      "Initializng Dataset with file path ::: ./train2.csv\n",
      "Loading Embeddings from Pkl\n",
      "Initializng Dataset with file path ::: ./test2.csv\n",
      "Url Column :2     \n",
      " Labels Column :3\n",
      "Using custom arch\n",
      "Model Successfully created\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mag8172\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path ./wandb/wandb/ wasn't writable, using system temp directory.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path ./wandb/wandb/ wasn't writable, using system temp directory\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/wandb/run-20240227_112336-l3epu8dy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-flower-64\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/runs/l3epu8dy\u001b[0m\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▍                                      | 1/7 [00:01<00:11,  1.98s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:02<00:00,  2.83it/s]\u001b[A\n",
      "Epoch [1/10], Loss: 1.0724\n",
      "Evaluating\n",
      "\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  8.98it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.4845, Precision: 0.5593, Recall: 0.4845, F1 Score: 0.4050\n",
      " 10%|████▍                                       | 1/10 [00:02<00:24,  2.70s/it]\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 236.10it/s]\u001b[A\n",
      "Epoch [2/10], Loss: 0.8455\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 309.41it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.6340, Precision: 0.6630, Recall: 0.6340, F1 Score: 0.6095\n",
      "\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 218.87it/s]\u001b[A\n",
      "Epoch [3/10], Loss: 0.7812\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 310.56it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.5258, Precision: 0.6364, Recall: 0.5258, F1 Score: 0.4611\n",
      "\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 220.01it/s]\u001b[A\n",
      "Epoch [4/10], Loss: 0.7930\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 306.05it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.7165, Precision: 0.7486, Recall: 0.7165, F1 Score: 0.7072\n",
      " 40%|█████████████████▌                          | 4/10 [00:02<00:03,  1.84it/s]\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 216.76it/s]\u001b[A\n",
      "Epoch [5/10], Loss: 0.6746\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 308.84it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.7680, Precision: 0.8371, Recall: 0.7680, F1 Score: 0.7657\n",
      "\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 232.78it/s]\u001b[A\n",
      "Epoch [6/10], Loss: 0.5849\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 278.40it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.7784, Precision: 0.8484, Recall: 0.7784, F1 Score: 0.7760\n",
      "\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 151.27it/s]\u001b[A\n",
      "Epoch [7/10], Loss: 0.5442\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 282.13it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.8505, Precision: 0.8577, Recall: 0.8505, F1 Score: 0.8500\n",
      " 70%|██████████████████████████████▊             | 7/10 [00:02<00:00,  3.61it/s]\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 215.58it/s]\u001b[A\n",
      "Epoch [8/10], Loss: 0.5362\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 310.94it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.8608, Precision: 0.8707, Recall: 0.8608, F1 Score: 0.8605\n",
      "\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 222.90it/s]\u001b[A\n",
      "Epoch [9/10], Loss: 0.5162\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 311.91it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.8608, Precision: 0.8654, Recall: 0.8608, F1 Score: 0.8599\n",
      "\n",
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 210.31it/s]\u001b[A\n",
      "Epoch [10/10], Loss: 0.5057\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 270.50it/s]\u001b[A\n",
      "66 66\n",
      "Accuracy: 0.8299, Precision: 0.8524, Recall: 0.8299, F1 Score: 0.8293\n",
      "100%|███████████████████████████████████████████| 10/10 [00:03<00:00,  3.23it/s]\n",
      "Evaluating\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 307.96it/s]\n",
      "66 66\n",
      "Accuracy: 0.8299, Precision: 0.8524, Recall: 0.8299, F1 Score: 0.8293\n",
      "Outputs saved at ./outputs.csv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.013 MB of 0.013 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          Epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           Loss █▅▄▅▃▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test Accuracy ▁▄▂▅▆▆███▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test F1 Score ▁▄▂▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Test Precision ▁▃▃▅▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    Test Recall ▁▄▂▅▆▆███▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          Epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           Loss 0.50568\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test Accuracy 0.8299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test F1 Score 0.82928\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Test Precision 0.85236\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    Test Recall 0.8299\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mazure-flower-64\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/runs/l3epu8dy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzNzM1MDkxNg==/version_details/v7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/wandb/run-20240227_112336-l3epu8dy/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out on mostly/ full labelled data now -- Code to convert labels and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/ipykernel_41893/4062936243.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/1zpMUVsyNfKFwkVUwul0pInCFjRCKFBwa4DFLZxTl5_g/export?gid=0&format=csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['afile', 'pno', 'full_url', 'Classification Layer 1', 'Images',\n",
       "       'redacted', 'Form (1) /Letter (2) /Photo (3) /Misc (4)', 'Revisit (x)',\n",
       "       'Sublayer Suggestions', 'Review label (1) Review Resolved (0)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Form (1) /Letter (2) /Photo (3) /Misc (4)\n",
       "NaN      9844\n",
       "1        9199\n",
       "2        3555\n",
       "4        2023\n",
       "3         662\n",
       "5          41\n",
       "6          24\n",
       "11          2\n",
       "`           1\n",
       "photo       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Form (1) /Letter (2) /Photo (3) /Misc (4)'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['afile', 'pno', 'full_url', 'Classification Layer 1', 'Images',\n",
       "       'redacted', 'Classification_1', 'Revisit (x)', 'Sublayer Suggestions',\n",
       "       'Review label (1) Review Resolved (0)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'Form (1) /Letter (2) /Photo (3) /Misc (4)':'Classification_1'})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "df.to_csv(\"./data/full_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification_1\n",
       "1        9199\n",
       "2        3555\n",
       "4        2023\n",
       "3         662\n",
       "5          41\n",
       "6          24\n",
       "11          2\n",
       "`           1\n",
       "photo       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Classification_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/ipykernel_41893/4100857509.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[labels_col] = df_filtered[labels_col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "labels_col = \"Classification_1\"\n",
    "df['pkl_index'] = df.index\n",
    "df_filtered = df[df[labels_col].isin([\"1\", \"2\", \"3\",\"4\"])]\n",
    "df_filtered[labels_col] = df_filtered[labels_col].astype(int)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = shuffle(df_filtered)\n",
    "\n",
    "# Split the DataFrame into features (X) and labels (y)\n",
    "X = df_shuffled.drop(labels_col, axis=1)  # Assuming 'Classification Layer 1' is the target column\n",
    "y = df_shuffled[labels_col]\n",
    "\n",
    "# Random downsampling class 1 to match the size of class 2\n",
    "# class_1_count = df_shuffled[labels_col].value_counts()[1]\n",
    "# class_2_count = df_shuffled[labels_col].value_counts()[2]\n",
    "# class_3_count = df_shuffled[labels_col].value_counts()[3]\n",
    "# class_4_count = \n",
    "\n",
    "classes = [1,2,3,4]\n",
    "classes_count = [df_shuffled[labels_col].value_counts()[i] for i in classes]\n",
    "classes_count.insert(0,0) # inserting dummmy 0\n",
    "\n",
    "# Downsampling class 1\n",
    "df_class_1 = df_shuffled[df_shuffled[labels_col] == 1]\n",
    "df_class_1_downsampled = df_class_1.sample(n=class_2_count, replace=False)\n",
    "\n",
    "# Combining class 2, class 3, and downsampled class 1\n",
    "df_combined = pd.concat([df_shuffled[df_shuffled[labels_col] == 2],\n",
    "                         df_shuffled[df_shuffled[labels_col] == 3],\n",
    "                         df_class_1_downsampled])\n",
    "\n",
    "df_combined[labels_col] = df_combined[labels_col] - 1 # keep labels from 0 - n\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_combined,\n",
    "                                                    df_combined[labels_col],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "X_train.to_csv('./data/train3.csv', index=False)\n",
    "X_test.to_csv('./data/test3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bringing down size to 662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/ipykernel_41893/3250734.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered[labels_col] = df_filtered[labels_col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "labels_col = \"Classification_1\"\n",
    "df['pkl_index'] = df.index\n",
    "df_filtered = df[df[labels_col].isin([\"1\", \"2\", \"3\",\"4\"])]\n",
    "df_filtered[labels_col] = df_filtered[labels_col].astype(int)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_shuffled = shuffle(df_filtered)\n",
    "\n",
    "# Split the DataFrame into features (X) and labels (y)\n",
    "X = df_shuffled.drop(labels_col, axis=1)  # Assuming 'Classification Layer 1' is the target column\n",
    "y = df_shuffled[labels_col]\n",
    "\n",
    "\n",
    "classes = [1,2,3,4]\n",
    "classes_count = [df_shuffled[labels_col].value_counts()[i] for i in classes]\n",
    "classes_count.insert(0,0) # inserting dummmy 0\n",
    "\n",
    "# Downsampling class 1\n",
    "df_shuffled_sampled = []\n",
    "class_size_to_bring_to = min(classes_count[1:])\n",
    "print(\"Bringing down size to\",class_size_to_bring_to)\n",
    "for cl in classes:\n",
    "    df_class_cl = df_shuffled[df_shuffled[labels_col] == cl]\n",
    "    df_shuffled_sampled.append(df_class_cl.sample(n=class_size_to_bring_to, replace=False))\n",
    "\n",
    "# Combining class 2, class 3, and downsampled class 1\n",
    "df_combined = pd.concat(df_shuffled_sampled)\n",
    "\n",
    "df_combined[labels_col] = df_combined[labels_col] - 1 # keep labels from 0 - n\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_combined,\n",
    "                                                    df_combined[labels_col],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "X_train.to_csv('./data/train4.csv', index=False)\n",
    "X_test.to_csv('./data/test4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2118, 530)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.columns).index('pkl_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method:: <class 'torchvision.transforms.transforms.Resize'> params:: [[256, 256]]\n",
      "method:: <class 'torchvision.transforms.transforms.Normalize'> params:: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
      "method:: <class 'torchvision.transforms.transforms.Resize'> params:: [[256, 256]]\n",
      "method:: <class 'torchvision.transforms.transforms.Normalize'> params:: [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]\n",
      "Loaded Configs\n",
      "Loading Embeddings from Pkl\n",
      "Initializng Dataset with file path ::: ./data/train4.csv\n",
      "Loading Embeddings from Pkl\n",
      "Initializng Dataset with file path ::: ./data/test4.csv\n",
      "Url Column :2     \n",
      " Labels Column :6\n",
      "Using custom arch\n",
      "Model Successfully created\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mag8172\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path ./wandb/wandb/ wasn't writable, using system temp directory.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path ./wandb/wandb/ wasn't writable, using system temp directory\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/wandb/run-20240410_083948-4pitz75r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33myouthful-snowflake-70\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/runs/4pitz75r\u001b[0m\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|██▌                                         | 1/17 [00:00<00:07,  2.01it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 19.36it/s]\u001b[A\n",
      "Epoch [1/10], Loss: 1.0776\n",
      "Evaluating\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 34.89it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.6736, Precision: 0.6910, Recall: 0.6736, F1 Score: 0.6753\n",
      " 10%|████▍                                       | 1/10 [00:01<00:09,  1.03s/it]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 204.75it/s]\u001b[A\n",
      "Epoch [2/10], Loss: 0.7840\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 292.36it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.7642, Precision: 0.7779, Recall: 0.7642, F1 Score: 0.7659\n",
      " 20%|████████▊                                   | 2/10 [00:01<00:03,  2.07it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 198.89it/s]\u001b[A\n",
      "Epoch [3/10], Loss: 0.6863\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 279.36it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.7943, Precision: 0.8004, Recall: 0.7943, F1 Score: 0.7952\n",
      " 30%|█████████████▏                              | 3/10 [00:01<00:02,  3.21it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 200.28it/s]\u001b[A\n",
      "Epoch [4/10], Loss: 0.6266\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 278.37it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.7925, Precision: 0.8083, Recall: 0.7925, F1 Score: 0.7931\n",
      " 40%|█████████████████▌                          | 4/10 [00:01<00:01,  4.33it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 194.37it/s]\u001b[A\n",
      "Epoch [5/10], Loss: 0.5854\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 273.96it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.8057, Precision: 0.8215, Recall: 0.8057, F1 Score: 0.8059\n",
      " 50%|██████████████████████                      | 5/10 [00:01<00:00,  5.34it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 203.41it/s]\u001b[A\n",
      "Epoch [6/10], Loss: 0.5578\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 274.55it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.8113, Precision: 0.8176, Recall: 0.8113, F1 Score: 0.8124\n",
      " 60%|██████████████████████████▍                 | 6/10 [00:01<00:00,  6.27it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 205.43it/s]\u001b[A\n",
      "Epoch [7/10], Loss: 0.5366\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 281.40it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.8208, Precision: 0.8216, Recall: 0.8208, F1 Score: 0.8210\n",
      " 70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  7.08it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 203.38it/s]\u001b[A\n",
      "Epoch [8/10], Loss: 0.5214\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 269.66it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.8283, Precision: 0.8308, Recall: 0.8283, F1 Score: 0.8285\n",
      " 80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  7.69it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 201.52it/s]\u001b[A\n",
      "Epoch [9/10], Loss: 0.5041\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 285.31it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.8302, Precision: 0.8324, Recall: 0.8302, F1 Score: 0.8301\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  8.17it/s]\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 206.40it/s]\u001b[A\n",
      "Epoch [10/10], Loss: 0.4938\n",
      "Evaluating\n",
      "\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 274.06it/s]\u001b[A\n",
      "18 18\n",
      "Accuracy: 0.8340, Precision: 0.8365, Recall: 0.8340, F1 Score: 0.8341\n",
      "100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  5.05it/s]\n",
      "Evaluating\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 268.95it/s]\n",
      "18 18\n",
      "Accuracy: 0.8340, Precision: 0.8365, Recall: 0.8340, F1 Score: 0.8341\n",
      "Outputs saved at ./outputs.csv\n",
      "Inference has been requested.. Performing inference..\n",
      "Loading Embeddings from Pkl\n",
      "Initializng Dataset with file path ::: ./data/full_data.csv\n",
      "100%|████████████████████████████████████████| 199/199 [00:00<00:00, 257.34it/s]\n",
      "Inference completed in 0.9055781364440918s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.016 MB of 0.016 MB uploaded\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          Epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           Loss █▄▃▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test Accuracy ▁▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test F1 Score ▁▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Test Precision ▁▅▆▇▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    Test Recall ▁▅▆▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          Epoch 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           Loss 0.4938\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test Accuracy 0.83396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  Test F1 Score 0.83414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Test Precision 0.83645\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    Test Recall 0.83396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33myouthful-snowflake-70\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/runs/4pitz75r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/ag8172/trial_run1/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzNzM1MDkxNg==/version_details/v9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/var/folders/2j/n6fpg8f54xb5ld5v6bg1wgl80000gn/T/wandb/run-20240410_083948-4pitz75r/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# putting a training run with all the data labelled so far \n",
    "\n",
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
